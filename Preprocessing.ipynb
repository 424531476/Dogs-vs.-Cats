{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1025 09:26:42.342046  9052 deprecation_wrapper.py:119] From c:\\program files\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1025 09:26:42.701431  9052 deprecation_wrapper.py:119] From c:\\program files\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "c:\\program files\\python37\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入模型完成\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionV3, Xception, ResNet50, VGG16\n",
    "from keras.applications import inception_v3, xception,resnet,vgg16\n",
    "from keras.models import Model,Input\n",
    "from keras.layers import Lambda,GlobalAveragePooling2D\n",
    "\n",
    "def getmodel(model,preprocess_input=None,image_size=(299, 299, 3),output_layer = None,include_top=False):\n",
    "    input_tensor = Input((image_size[0], image_size[1], image_size[2]))\n",
    "    if preprocess_input:\n",
    "        input_tensor = Lambda(preprocess_input)(input_tensor)\n",
    "    base_model = model(input_tensor=input_tensor, weights='imagenet', include_top=include_top)\n",
    "    output = base_model.output\n",
    "    if output_layer is not None:\n",
    "        output = base_model.layers[output_layer].output\n",
    "    return Model(base_model.input, output)\n",
    "InceptionV3_top_model = getmodel(InceptionV3, inception_v3.preprocess_input, include_top=True)\n",
    "InceptionV3_model = getmodel(InceptionV3, inception_v3.preprocess_input)\n",
    "InceptionV3_ave_model = Model(InceptionV3_model.input, GlobalAveragePooling2D()(InceptionV3_model.output))\n",
    "# InceptionV3_ave_model.summary()\n",
    "\n",
    "Xception_top_model = getmodel(Xception,xception.preprocess_input, include_top=True)\n",
    "Xception_model = getmodel(Xception,xception.preprocess_input)\n",
    "Xception_ave_model = Model(Xception_model.input, GlobalAveragePooling2D()(Xception_model.output))\n",
    "# Xception_ave_model.summary()\n",
    "\n",
    "ResNet50_top_model = getmodel(ResNet50, resnet.preprocess_input, include_top=True)\n",
    "ResNet50_model = getmodel(ResNet50, resnet.preprocess_input)\n",
    "ResNet50_ave_model = Model(ResNet50_model.input, GlobalAveragePooling2D()(ResNet50_model.output))\n",
    "# ResNet50_ave_model.summary()\n",
    "\n",
    "# VGG16_top_model = getmodel(VGG16, vgg16.preprocess_input,include_top=True,image_size=(224, 224, 3))\n",
    "VGG16_model = getmodel(VGG16, vgg16.preprocess_input,output_layer=18)\n",
    "VGG16_ave_model = Model(VGG16_model.input, GlobalAveragePooling2D()(VGG16_model.output))\n",
    "# VGG16_ave_model.summary()\n",
    "\n",
    "print('载入模型完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "def load_image(img,image_size=(299, 299)):\n",
    "    if type(img) == str:\n",
    "        img = image.load_img(img, target_size=image_size)\n",
    "        img = image.img_to_array(img)\n",
    "        return np.expand_dims(img, axis=0)\n",
    "    if type(img) == np.ndarray:\n",
    "        img = cv2.resize(img,image_size)\n",
    "        return np.expand_dims(img, axis=0)\n",
    "    if isinstance(img,(tuple,list)):\n",
    "        ret = [load_image(i)for i in img]\n",
    "        return np.vstack(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集一共12445张猫图 ['..\\\\data\\\\train\\\\cat.0.jpg', '..\\\\data\\\\train\\\\cat.1.jpg', '..\\\\data\\\\train\\\\cat.10.jpg', '..\\\\data\\\\train\\\\cat.100.jpg', '..\\\\data\\\\train\\\\cat.1000.jpg']\n",
      "训练集一共12469张狗图 ['..\\\\data\\\\train\\\\dog.0.jpg', '..\\\\data\\\\train\\\\dog.1.jpg', '..\\\\data\\\\train\\\\dog.10.jpg', '..\\\\data\\\\train\\\\dog.100.jpg', '..\\\\data\\\\train\\\\dog.1000.jpg']\n",
      "测试集一共12500张图 ['..\\\\data\\\\test\\\\1.jpg', '..\\\\data\\\\test\\\\2.jpg', '..\\\\data\\\\test\\\\3.jpg', '..\\\\data\\\\test\\\\4.jpg', '..\\\\data\\\\test\\\\5.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_filenames(_type):\n",
    "    train_dir = r'..\\data\\train'\n",
    "    train_filenames = os.path.join(train_dir, '%s.*.jpg'%_type)\n",
    "    return glob(train_filenames)\n",
    "def get_test_filenames():\n",
    "    test_dir = r'..\\data\\test'\n",
    "    test_filenames = os.path.join(test_dir, '*.jpg')\n",
    "    test_filenames =glob(test_filenames)\n",
    "    def key(filename):\n",
    "        filename = os.path.split(filename)[1]\n",
    "        filename = os.path.splitext(filename)[0]\n",
    "        return int(filename)\n",
    "    test_filenames.sort(key=key)\n",
    "    return test_filenames\n",
    "\n",
    "train_cat_filenames = get_train_filenames('cat')\n",
    "train_dog_filenames = get_train_filenames('dog')\n",
    "test_filenames = get_test_filenames()\n",
    "\n",
    "print('训练集一共%d张猫图'%len(train_cat_filenames), train_cat_filenames[:5])\n",
    "print('训练集一共%d张狗图'%len(train_dog_filenames), train_dog_filenames[:5])\n",
    "print('测试集一共%d张图'%len(test_filenames), test_filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理猫异常输出\n",
      "开始处理狗异常输出\n",
      "异常值处理完毕用时0s\n",
      "剔除异常数据后训练集一共12445张猫图 ['..\\\\data\\\\train\\\\cat.0.jpg', '..\\\\data\\\\train\\\\cat.1.jpg', '..\\\\data\\\\train\\\\cat.10.jpg', '..\\\\data\\\\train\\\\cat.100.jpg', '..\\\\data\\\\train\\\\cat.1000.jpg']\n",
      "剔除异常数据后训练集一共12469张狗图 ['..\\\\data\\\\train\\\\dog.0.jpg', '..\\\\data\\\\train\\\\dog.1.jpg', '..\\\\data\\\\train\\\\dog.10.jpg', '..\\\\data\\\\train\\\\dog.100.jpg', '..\\\\data\\\\train\\\\dog.1000.jpg']\n",
      "测试集一共12500张图 ['..\\\\data\\\\test\\\\1.jpg', '..\\\\data\\\\test\\\\2.jpg', '..\\\\data\\\\test\\\\3.jpg', '..\\\\data\\\\test\\\\4.jpg', '..\\\\data\\\\test\\\\5.jpg']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from time import time\n",
    "target_class_dogs = ['n02085620','n02085782','n02085936','n02086079','n02086240','n02086646','n02086910','n02087046','n02087394','n02088094','n02088238',\n",
    "        'n02088364','n02088466','n02088632','n02089078','n02089867','n02089973','n02090379','n02090622','n02090721','n02091032','n02091134',\n",
    "        'n02091244','n02091467','n02091635','n02091831','n02092002','n02092339','n02093256','n02093428','n02093647','n02093754','n02093859',\n",
    "        'n02093991','n02094114','n02094258','n02094433','n02095314','n02095570','n02095889','n02096051','n02096177','n02096294','n02096437',\n",
    "        'n02096585','n02097047','n02097130','n02097209','n02097298','n02097474','n02097658','n02098105','n02098286','n02098413','n02099267',\n",
    "        'n02099429','n02099601','n02099712','n02099849','n02100236','n02100583','n02100735','n02100877','n02101006','n02101388','n02101556',\n",
    "        'n02102040','n02102177','n02102318','n02102480','n02102973','n02104029','n02104365','n02105056','n02105162','n02105251','n02105412',\n",
    "        'n02105505','n02105641','n02105855','n02106030','n02106166','n02106382','n02106550','n02106662','n02107142','n02107312','n02107574',\n",
    "        'n02107683','n02107908','n02108000','n02108089','n02108422','n02108551','n02108915','n02109047','n02109525','n02109961','n02110063',\n",
    "        'n02110185','n02110341','n02110627','n02110806','n02110958','n02111129','n02111277','n02111500','n02111889','n02112018','n02112137',\n",
    "        'n02112350','n02112706','n02113023','n02113186','n02113624','n02113712','n02113799','n02113978']\n",
    "target_class_cats=['n02123045','n02123159','n02123394','n02123597','n02124075','n02125311','n02127052']\n",
    "\n",
    "def remove_file_excep(filename,target_classes):\n",
    "    excep_dir = '..\\data\\exception'\n",
    "    img = load_image(filename)\n",
    "    models = [(InceptionV3_top_model,inception_v3),\n",
    "              (Xception_top_model,xception),\n",
    "              (ResNet50_top_model,resnet)]\n",
    "    for model in models:\n",
    "        preds = model[0].predict(img)\n",
    "        dps = model[1].decode_predictions(preds)[0]\n",
    "        for dp in dps:\n",
    "            if dp[0] in target_classes:\n",
    "                return\n",
    "    print('\\n移除文件', filename)\n",
    "    dst_filename = os.path.join(excep_dir, os.path.split(filename)[1])\n",
    "#     shutil.copyfile(filename,dst_filename)\n",
    "    os.rename(filename, dst_filename)\n",
    "\n",
    "def remove_excep(train_filenames,target_classes):\n",
    "    for i in range(len(train_filenames)):\n",
    "        print('\\r训练集异常值处理%d/%d'%(i+1,len(train_filenames)), end='')\n",
    "        filename = train_filenames[i]\n",
    "        remove_file_excep(filename,target_classes)\n",
    "\n",
    "t0 = time()\n",
    "print('开始处理猫异常输出')\n",
    "train_cat_filenames = get_train_filenames('cat')\n",
    "# remove_excep(train_cat_filenames,target_class_cats)\n",
    "print('开始处理狗异常输出')\n",
    "train_dog_filenames = get_train_filenames('dog')\n",
    "# remove_excep(train_dog_filenames,target_class_dogs)\n",
    "print('异常值处理完毕用时%ds' % (time()-t0))\n",
    "\n",
    "train_cat_filenames = get_train_filenames('cat')\n",
    "train_dog_filenames = get_train_filenames('dog')\n",
    "X_test_filenames = get_test_filenames()\n",
    "print('剔除异常数据后训练集一共%d张猫图'%len(train_cat_filenames), train_cat_filenames[:5])\n",
    "print('剔除异常数据后训练集一共%d张狗图'%len(train_dog_filenames), train_dog_filenames[:5])\n",
    "print('测试集一共%d张图'%len(test_filenames), test_filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始预处理\n",
      "X_train_cat_InceptionV3已存在\n",
      "X_train_cat_Xception已存在\n",
      "X_train_cat_ResNet50已存在\n",
      "X_train_cat_VGG16已存在\n",
      "cat处理完成用时0s\n",
      "X_train_dog_InceptionV3已存在\n",
      "X_train_dog_Xception已存在\n",
      "X_train_dog_ResNet50已存在\n",
      "X_train_dog_VGG16已存在\n",
      "dog处理完成用时0s\n",
      "X_test_InceptionV3已存在\n",
      "X_test_Xception已存在\n",
      "X_test_ResNet50已存在\n",
      "X_test_VGG16已存在\n",
      "测试集处理完成用时0s\n"
     ]
    }
   ],
   "source": [
    "# 提取特征保存fdf5\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "from time import time\n",
    "\n",
    "def preprocess_save(x_data,name, model,image_size=(299, 299)):\n",
    "    def preprocess(images, model,image_size=(299, 299),  show_log=False):\n",
    "        X_preprocess = list()\n",
    "        batch_size = 10\n",
    "        for i in range(math.ceil(len(images)/batch_size)):\n",
    "            batch_image = images[i*batch_size:(i+1)*batch_size]\n",
    "            batch_data = [load_image(img,image_size) for img in batch_image]\n",
    "            batch_data = np.vstack(batch_data)\n",
    "        #     print(batch_data.shape)\n",
    "            X_preprocess.append(model.predict(batch_data))\n",
    "            if show_log:\n",
    "                print('\\r%d/%d'%(i + 1, math.ceil(len(images)/batch_size)),end='')\n",
    "        if show_log:\n",
    "            print('\\r', end='')\n",
    "        X_preprocess = np.vstack(X_preprocess)\n",
    "        return X_preprocess\n",
    "\n",
    "    with h5py.File(\"preprocess.hdf5\", \"a\") as f:\n",
    "        if name in f.keys():\n",
    "            print('%s已存在' % name)\n",
    "            return\n",
    "    batch_size = 1000\n",
    "    for i in range(math.ceil(len(x_data)/batch_size)):\n",
    "        name_temp = '%s_%d' % (name,i)\n",
    "        with h5py.File(\"preprocess.hdf5\", \"a\") as f:\n",
    "            if name_temp in f.keys():\n",
    "                continue\n",
    "            t0 = time()\n",
    "            X_temp = preprocess(x_data[i*batch_size:(i+1)*batch_size],\n",
    "                                model=model,\n",
    "                                image_size=image_size,\n",
    "                                show_log=True)\n",
    "            f.create_dataset(name_temp,data=X_temp)\n",
    "            print('%s_%d处理完成%d/%d用时%ds'%(name, i, (i+1)*batch_size, len(x_data), time()-t0), \n",
    "                  X_temp.shape)\n",
    "    X_merge = list()\n",
    "    with h5py.File(\"preprocess.hdf5\", \"a\") as f:\n",
    "        for i in range(math.ceil(len(x_data)/batch_size)):\n",
    "            name_temp = '%s_%d' % (name,i)\n",
    "            X_merge.append(np.array(f[name_temp]))\n",
    "            del f[name_temp]\n",
    "        X_merge = np.vstack(X_merge)\n",
    "        f.create_dataset(name,data=X_merge)\n",
    "    print('%s处理完成'%name)\n",
    "\n",
    "\n",
    "\n",
    "print('开始预处理')\n",
    "t0 = time()\n",
    "preprocess_save(train_cat_filenames,'X_train_cat_InceptionV3',model=InceptionV3_ave_model)\n",
    "preprocess_save(train_cat_filenames,'X_train_cat_Xception',model=Xception_ave_model)\n",
    "preprocess_save(train_cat_filenames,'X_train_cat_ResNet50',model=ResNet50_ave_model)\n",
    "preprocess_save(train_cat_filenames,'X_train_cat_VGG16',model=VGG16_ave_model)\n",
    "print('cat处理完成用时%ds' % (time() - t0))\n",
    "t0 = time()\n",
    "preprocess_save(train_dog_filenames,'X_train_dog_InceptionV3',model=InceptionV3_ave_model)\n",
    "preprocess_save(train_dog_filenames,'X_train_dog_Xception',model=Xception_ave_model)\n",
    "preprocess_save(train_dog_filenames,'X_train_dog_ResNet50',model=ResNet50_ave_model)\n",
    "preprocess_save(train_dog_filenames,'X_train_dog_VGG16',model=VGG16_ave_model)\n",
    "print('dog处理完成用时%ds' % (time()-t0))\n",
    "\n",
    "t0 = time()\n",
    "preprocess_save(X_test_filenames,'X_test_InceptionV3',model=InceptionV3_ave_model)\n",
    "preprocess_save(X_test_filenames,'X_test_Xception',model=Xception_ave_model)\n",
    "preprocess_save(X_test_filenames,'X_test_ResNet50',model=ResNet50_ave_model)\n",
    "preprocess_save(X_test_filenames,'X_test_VGG16',model=VGG16_ave_model)\n",
    "print('测试集处理完成用时%ds' % (time()-t0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
